
@Article{Chaumette04a,
  author =	 {Chaumette, F.},
  title =	 {Image moments: a general and useful set of features for
                  visual servoing},
  journal =	 {IEEE Trans. on Robotics},
  year =	 {2004},
  month =	 aug,
  number =	 {4},
  volume =	 {20},
  pages =	 {713-723},
  abstract =	 {In this paper, we determine the analytical form of the
                  interaction matrix related to any moment that can be computed
                  from segmented images. The derivation method we present is
                  based on Green's theorem. We apply this general result to
                  classical geometrical primitives. We then consider using
                  moments in image-based visual servoing. For that, we select
                  six combinations of moments to control the six degrees of
                  freedom of the system. These features are particularly
                  adequate if we consider a planar object and the
                  configurations such that the object and camera planes are
                  parallel at the desired position. The experimental results we
                  present show that a correct behavior of the system is
                  obtained if we consider either a simple symmetrical object or
                  a planar object with complex and unknown shape.},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_itro_chaumette.pdf},
  keyword =	 {visual servoing, robotics, modeling}
}

@InProceedings{Chaumette04b,
  author =	 {Chaumette, F. and Marchand, E.},
  title =	 {Recent results in visual servoing for robotics applications},
  booktitle =	 {8th ESA Workshop on Advanced Space test du \&, Technologies for Robotics
                  and Automation, ASTRA 2004.},
  pages =	 {471-478},
  year =	 {2004},
  abstract =	 {This paper presents new advances in the field of visual
                  servoing for robot positioning tasks with respect to complex
                  objects. A pose estimation and tracking algorithm is
                  described to deal with real objects whose 3D~model is
                  known. Experimental results using image motion estimation are
                  also presented. },
  address =	 {Noordwijk, The Netherlands},
  adresse =	 {Noordwijk, Pays-Bas},
  month =	 {nov},
  keyword =	 {virtual visual servoing, model-based tracking, pose, visual
                  servoing, robotics, tracking},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_astra_chaumette.pdf},
}

@InProceedings{Collewet04a,
  Author =	 {Collewet, C. and Alhaj, A. and Chaumette, F.},
  title =	 {Model-free visual servoing on complex images based on 3D
                  reconstruction},
  booktitle =	 {IEEE Int. Conf. on Robotics and Automation ICRA'04},
  pages =	 {751-756},
  year =	 {2004},
  volume =	 {1},
  address =	 {New Orleans, LA},
  adresse =	 {La Nouvelle-Orléans, Louisiane},
  month =	 April,
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_icra_collewet.pdf},
  abstract =	 {We present a way to achieve positioning tasks by model-free
                  visual servoing in the case of planar and motionless objects
                  whose shape is unknown. Emphasize is made on the algorithm of
                  3d reconstruction which allows to synthetize easily the
                  control law. More precisely, the reconstruction phase is
                  based on the measurement of the 2D displacements in a region
                  of interest and on the measurement of the camera
                  velocity. However, we will show that the proposed algorithm
                  is robust with respect to nonaccurate values of this
                  velocity. 2D displacements rather than 2D motions are used to
                  remove the assumption that the acquisition rate has to be
                  high. In addition, a particular attention is paid to the
                  complex case of large displacements to access high camera
                  velocities. Once the parameters of the plane are sufficiently
                  stable, a visual servoing scheme is used to control the
                  orientation of the camera with respect to the object and to
                  ensure that it remains in the camera eld of view for any
                  desired orientation. The 3D reconstruction phase is
                  maintained active during the servoing to improve the accuracy
                  of the parameters and, consequently, to obtain a small
                  positioning error. Experimental results validate the proposed
                  approach.},
  keyword =	 {visual servoing, robotics}
}

@InProceedings{Comport04a,
  author =	 {Comport, A.I. and Pressigout, M. and Marchand, E. and
                  Chaumette, F.},
  title =	 {Une loi de commande robuste aux mesures aberrantes en
                  asservissement visuel},
  booktitle =	 {14ème Congrès Francophone AFRIF-AFIA de Reconnaissance des
                  Formes et Intelligence Artificielle, RFIA'04},
  OPTpages =	 {},
  year =	 {2004},
  OPTvolume =	 {},
  address =	 {Toulouse, France},
  type =	 nationale,
  month =	 {Janvier},
  abstract =	 { Les techniques actuelles d'asservissement visuel ne prennent
                  pas en compte d'éventuelles mesures aberrantes, laissant
                  souvent cet aspect au seul traitement d'images. Nous
                  présentons dans cet article une loi de commande qui permet
                  simultanément de réaliser la tâche d'asservissement visuel et
                  de prendre en compte des données erronées. Cette méthode
                  permet de considérer une grande variété d'erreur~: bruit dans
                  l'extraction des indices visuels, faibles erreurs de suivi,
                  et importantes erreurs de mise en correspondance entre
                  primitives courantes et désirées. La méthode retenue repose
                  sur l'utilisation des techniques d'estimation statistique
                  robuste et, en particulier, des M-estimateurs. Ces
                  M-estimateurs sont introduits directement dans la loi de
                  commande. Une étude sur la robustesse et la stabilité locale
                  de cette nouvelle loi de commande est proposée. Des résultats
                  expérimentaux sont finalement présentés et démontrent
                  l'efficacité de la loi de commande pour des tâches de
                  positionnement en présence d'erreurs plus ou moins
                  importantes dans les données image. },
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_rfia_comport.pdf},
  keyword =	 {visual servoing, robotics}
}

@InProceedings{Comport04b,
  author =	 {Comport, A.I. and Tahri, O. and Marchand, E. and Chaumette,
                  F.},
  title =	 {Visual servoing with respect to complex objects},
  booktitle =	 {Int. Symp. on Robotics, ISR'04},
  OPTpages =	 {},
  year =	 {2004},
  OPTeditor =	 {},
  OPTvolume =	 {},
  OPTnumber =	 {},
  abstract =	 {This paper presents new advances in the field of visual
                  servoing. More precisely, we consider the case where complex
                  objects are observed by a camera. In a first part, planar
                  objects of unknown shape are considered using image moments
                  as input of the image-based control law. In the second part,
                  a pose estimation and tracking algorithm is described to deal
                  with real objects whose 3D model is known. For each case,
                  experimental results obtained with an eye-in-hand system are
                  presented.},
  address =	 {Paris, France},
  month =	 {Mars},
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_isr_comport.pdf},
  keyword =	 {virtual visual servoing, model-based tracking, pose, visual
                  servoing, robotics, tracking, modelisation}
}

@InProceedings{Comport04c,
  Author =	 {Comport, A.I. and Marchand, E. and Chaumette, F.},
  Title =	 {Object-based visual 3D tracking of articulated objects via
                  kinematic sets},
  BookTitle =	 {IEEE Workshop on Articulated and Non-Rigid Motion},
  Address =	 {Washington, DC},
  Month =	 {June},
  Year =	 {2004},
  abstract =	 {A theoretical framework based on robotics techniques is
                  introduced for visual tracking of parametric non-rigid
                  multi-body objects. It is based on an a-priori model of the
                  object including a general mechanical link description. The
                  objective equation is defined in the object-based coordinate
                  system and non-linear minimization relates to the movement of
                  the object and not the camera. This results in simultaneously
                  estimating all degrees of freedom between the object s last
                  known position relative to its previous position as well as
                  internal articulated parameters. A new kinematic-set
                  formulation takes into account that articulated degrees of
                  freedom are directly observable from the camera and therefore
                  their estimation does not need to pass via a kinematicchain
                  back to the root. By doing this the tracking techniques are
                  efficient and precise leading to real-time performance and
                  accurate measurements. The system is locally based upon an
                  accurate modeling of a distance criteria. A general method is
                  derived for defining any type of mechanical link and
                  experimental results show prismatic, rotational and
                  helicoidal type links. A statistical M-estimation technique
                  is applied to improve robustness. A monocular camera system
                  was used as a real-time sensor to verify the theory. } ,
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_wkanm_comport.pdf},
doi = {http://dx.doi.org/10.1109/CVPR.2004.136},
  keyword =	 {virtual visual servoing, tracking, model-based tracking,
                  pose, articulated}
}

@InProceedings{Comport04d,
  Author =	 {Comport, A.I. and Marchand, E. and Chaumette, F.},
  Title =	 {Complex articulated object tracking},
  BookTitle =	 {Int. Workshop on articulated motion and deformable objects,
                  AMDO'04},
  pages =	 {189-201},
  editor =	 {Perales, J.F. and Draper, B.A.},
  volume =	 3179,
  series =	 {Lecture Notes in Computer Science},
  Address =	 {Palma de Mallorca, Spain},
  Adresse =	 {Palma de Majorque, Espagne},
  Month =	 {septembre},
  keyword =	 {virtual visual servoing, model-based tracking, pose,
                  articulated, tracking},
  Year =	 {2004},
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_wkamdo_comport.pdf}
}

@InProceedings{Favet04a,
  author =	 {Fauvet, B. and Bouthemy, P. and Gros, P. and Spindler, F.},
  title =	 { A Geometrical Key-Frame Selection Method Exploiting Dominant
                  Motion Estimation in Video},
  series =	 {Lecture Notes in Computer Science},
  volume =	 3115,
  booktitle =	 {Int. Conf. on Image and Video Retrieval, CIVR 2004},
  pages =	 {419 - 427},
  year =	 {2004},
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_cvir_fauvet.pdf},
  abstract =	 { We describe an original method for selecting key frames to
                  represent the content of every shot in a video. We aim at
                  spatially sampling in an uniform way the coverage of the
                  scene viewed in each shot. Our method exploits the
                  computation of the dominant image motion (assumed to be due
                  to the camera motion) and mainly relies on geometrical
                  properties related to the incremental contribution of a frame
                  in the considered shot. We also present a refinement of the
                  proposed method to obtain a more accurate representation of
                  the scene, but at the cost of a higher computation time, by
                  considering the iterative minimization of an appropriate
                  energy function. We report experimental results on sports
                  videos and documentaries which demonstrate the accuracy and
                  the efficiency of the proposed approach. },
  address =	 {Dublin, Eire},
  adresse =	 {Dublin, Irlande},
  month =	 juillet,
}

@InProceedings{Comport04e,
  Author =	 {Comport, A.I. and Marchand, E. and Chaumette, F.},
  Title =	 {Robust model-based tracking for robot vision},
  booktitle =	 {IEEE/RSJ Int. Conf. on Intelligent Robots and Systems,
                  IROS'04},
  pages =	 {692--697},
  year =	 {2004},
  adresse =	 {Sendai, Japon},
  address =	 {Sendai, Japan},
  month =	 {september},
  volume =	 {1},
  abstract =	 { This paper proposes a real-time, robust and efficient 3D
                  model-based tracking algorithm for visual servoing. A virtual
                  visual servoing approach is used for monocular 3D
                  tracking. This method is similar to more classical non-linear
                  pose computation techniques. A concise method for derivation
                  of efficient distance-to-contour interaction matrices is
                  described. An oriented edge detector is used in order to
                  provide real-time tracking of points normal to the object
                  contours. Robustness is obtained by integrating a M-estimator
                  into the virtual visual control law via an iteratively
                  re-weighted least squares implementation. The method
                  presented in this paper has been validated on several 2D 1/2
                  visual servoing experiments considering various
                  objects. Results show the method to be robust to occlusion,
                  changes in illumination and miss-tracking.},
doi = {http://dx.doi.org/10.1109/IROS.2004.1389433},
  keyword =	 {visual servoing, virtual visual servoing, tracking, pose},
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_iros_comport.pdf},
}

@InProceedings{Lapreste04a,
  Author =	 {Lapresté, J.-T. and Jurie, F. and Dhome, M. and Chaumette,
                  F.},
  Title =	 {Nouvelle approche pour le calcul du jacobien inverse en
                  asservissement visuel 2D},
  BookTitle =	 {14ème Congrès Francophone AFRIF-AFIA de Reconnaissance des
                  Formes et Intelligence Artificielle, RFIA 2004},
  Address =	 {Toulouse, France},
  Month =	 {January},
  type =	 nationale,
  Year =	 {2004},
  keyword =	 {visual servoing, robotics},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_rfia_lapreste.pdf},
  keyword =	 {visual servoing, robotics}
}

@InProceedings{Lapreste04b,
  Author =	 {Lapresté, J.-T. and Jurie, F. and Dhome, M. and Chaumette,
                  F.},
  title =	 {An Efficient Method to Compute the Inverse Jacobian Matrix in
                  Visual Servoing},
  booktitle =	 {IEEE Int. Conf. on Robotics and Automation, ICRA'04},
  pages =	 {727-732},
  year =	 {2004},
  volume =	 {1},
  address =	 {New Orleans, LA},
  adresse =	 {La Nouvelle-Orléans, Louisiane},
  month =	 April,
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_icra_lapreste.pdf},
  abstract =	 {The paper presents a method for estimating the inverse
                  Jacobian matrix of a function, without computing the direct
                  Jacobian matrix. The resulting inverse Jacobian matrix is
                  shown to perform much better in modelling a relation $\theta=
                  f^{-1}(x)$ than the classical Moore-Penrose inverse $J^+_f$
                  . Theoretical insight as well as comparisons in the domain of
                  visual servoing are provided to demonstrate this assertion.},
  keyword =	 {visual servoing, robotics}
}

@InProceedings{Li04a,
  Author =	 {Li, P. and Chaumette, F.},
  Title =	 {Image Cues Fusion for Contour Tracking Based on Particle
                  Filter},
  BookTitle =	 {Int. Workshop on articulated motion and deformable objects,
                  AMDO'04},
  series =	 {Lecture Notes in Computer Science},
  pages =	 {99-107},
  volume =	 3179,
  editor =	 {Perales, J.F. and Draper, B.A.},
  Address =	 {Palma de Mallorca, Spain},
  Adresse =	 {Palma de Majorque, Espagne},
  Month =	 {septembre},
  keyword =	 {tracking, tracking 2d},
  Year =	 {2004},
  abstract =	 {Particle filter is a powerful algorithm to deal with
                  non-linear and non-Gaussian tracking problems. However the
                  algorithm relying only upon one image cue often fails in
                  challenging scenarios. To overcome this, the paper first
                  presents a color likelihood to capture color distribution of
                  the object based on Bhattacharry coefficient, and a structure
                  likelihood representing high level knowledge regarding the
                  object. Together with the widely used edge likelihood, the
                  paper further proposes a straightforward image cues fusion
                  for object tracking in the framework of particle filter,
                  under assumption that the visual measurement of each image
                  cue is independent of each other. The experiments on real
                  image sequences have shown that the method is effective,
                  robust to illumination changes, pose variations and complex
                  background.},
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_wkamdo_li.pdf}
}

@InProceedings{Mansard04a,
  author =	 {Mansard, N. and Chaumette, F.},
  title =	 {Tasks sequencing for visual servoing},
  booktitle =	 {IEEE/RSJ Int. Conf. on Intelligent Robots and Systems,
                  IROS'04},
  volume =	 {1},
  pages =	 {992-997},
  year =	 {2004},
  adresse =	 {Sendai, Japon},
  address =	 {Sendai, Japan},
  month =	 {september},
  keyword =	 {visual servoing, robotics, redondance},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_iros_mansard.pdf},
  abstract =	 { Classical visual servoing approaches tend to constrain all
                  degrees of freedom (DOF) of the robot during a task s
                  execution. This may lead to singularities, force the robot
                  into its joint limits or allow the visual features to leave
                  the image. In this article a new approach is proposed. The
                  key idea of this work is to control the robot with a very
                  under-constrained task when it is far of the desired
                  position, and to incrementally constrain the global task by
                  adding further tasks as the robot moves closer to the goal. A
                  method is first proposed that stacks elementary tasks until
                  the robot is fully constrained. To insure the continuity of
                  the articular velocities when adding constraints, a new
                  control law is then proposed. Experiments that prove the
                  interest of the approach are also provided.}
}

@InProceedings{Marchand04a,
  author =	 {Marchand, E. and Comport, A.I. and Chaumette, F.},
  title =	 {Improvements in robust 2D visual servoing},
  booktitle =	 {IEEE Int. Conf. on Robotics and Automation, ICRA'04},
  pages =	 {745-750},
  year =	 {2004},
  volume =	 {1},
  address =	 {New Orleans, LA},
  adresse =	 {La Nouvelle-Orléans, Louisiane},
  keyword =	 {visual servoing, robotics, robust visual servoing, robust},
  month =	 {Avril},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_icra_marchand.pdf},
  doi = "http://dx.doi.org/10.1109/ROBOT.2004.1307238},
  abstract =	 { A fundamental step towards broadening the use of real world
                  image-based visual servoing is to deal with the important
                  issues of reliability and robustness. In order to address
                  this issue, a closed loop control law is proposed that
                  simultaneously accomplishes a visual servoing task and is
                  robust to a general class of image processing errors. This is
                  achieved with the application of widely accepted statistical
                  techniques of robust M-estimation. Furthermore improvement
                  have been added in the weight computation process: memory,
                  initialization. Indeed, when the error between current visual
                  features and desired ones are large, which occurs when large
                  robot displacement are required, M-estimator may not detect
                  outliers. To address this point, the method we propose to
                  initialize the confidence in each feature is based on the
                  LMedS estimators. Experimental results are presented which
                  demonstrate visual servoing tasks which resist severe outlier
                  contamination.},
  keyword =	 {visual servoing, robotics}
}

@InProceedings{Marchand04b,
  author =	 {Marchand, E. and Chaumette, F.},
  title =	 {Features tracking for visual servoing purpose},
  booktitle =	 {Advances in Robot Vision - From Domestic Environments to
                  Medical Applications},
  editor =	 {Kragic, D. and Christensen, H.},
  pages =	 {10--20},
  year =	 {2004},
  OPTvolume =	 {},
  address =	 {Sendai, Japan},
  adresse =	 {Sendai, Japon},
  keyword =	 {virtual visual servoing, model-based tracking, pose, visual
                  servoing, robotics, tracking},
  month =	 sep,
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_wkiros_marchand.pdf}
}

@PhdThesis{Marchand04c,
  author =	 {Marchand, E.},
  title =	 {Commande d'une caméra réelle ou virtuelle dans des mondes
                  réels ou virtuels},
  school =	 { Université de Rennes 1, Mention informatique},
  year =	 {2004},
  month =	 {nov},
  url =
                 {http://www.irisa.fr/lagadic/pdf/2004_hdr_marchand.pdf},
  note =	 {http://www.irisa.fr/lagadic/team/marchand/hdr/hdr.html},
  type =	 {hdr},
  keyword =	 {visual servoing, robotics, virtual visual servoing,
                  model-based tracking, pose, visual servoing, robotics,
                  tracking, animation},
}

@InProceedings{Mezouar04a,
  author =	 {Mezouar, Y. and {Hadj Abdelkader}, H. and Martinet, P. and
                  Chaumette, F.},
  title =	 {Visual Servoing from 3D Straight Lines with Central
                  Catadioptric Cameras},
  booktitle =	 {Fifth Workshop on Omnidirectional Vision, Omnivis'2004},
  OPTpages =	 {},
  year =	 {2004},
  OPTvolume =	 {},
  url =		 {http://www.irisa.fr/lagadic/pdf/2004_omnivis_mezouar.pdf},
  abstract =	 {In this paper we consider the problem of controlling the six
                  degrees of freedom of a manipulator using the projection of
                  3D lines in the image plane of central catadioptric
                  systems. Most of the effort in visual servoing are devoted to
                  points, only few works have investigated the use of lines in
                  visual servoing with traditional cameras and none has
                  explored the case of omnidirectional cameras. First a generic
                  interaction matrix for the projection of 3D straight lines is
                  derived from the projection model of the entire class of
                  central catadioptric cameras. Then an image-based control law
                  is designed and validated through simulation results.},
  address =	 {Prague, Czech Republic},
  adresse =	 {Prague, République Tchaèque},
  month =	 {May},
  keyword =	 {visual servoing, robotics, omnidirectional vision}
}

@InProceedings{Mezouar04b,
  author =	 {Mezouar, Y. and {Haj Abdelkader}, H. and Martinet, P. and
                  Chaumette, F.},
  title =	 {Central Catadioptric Visual Servoing From 3D Straight Lines},
  booktitle =	 {IEEE/RSJ Int. Conf. on Intelligent Robots and Systems,
                  IROS'04},
  volume =	 {1},
  pages =	 {343-349},
  year =	 {2004},
  adresse =	 {Sendai, Japon},
  address =	 {Sendai, Japan},
  month =	 {september},
  keyword =	 {visual servoing, robotics, omnidirectional vision},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_iros_mezouar.pdf},
  abstract =	 {In this paper we consider the problem of controlling a
                  robotic system using the projection of 3D lines in the image
                  plane of central catadioptric systems. Most of the effort in
                  visual servoing are devoted to points, only few works have
                  investigated the use of lines in visual servoing with
                  traditional cameras and none has explored the case of
                  omnidirectional cameras. First a generic central catadioptric
                  interaction matrix for the projection of 3D straight lines is
                  derived from the projection model of an entire class of
                  camera. Then an image-based control law is designed and
                  validated through simulation results.}
}

@InProceedings{Pages04a,
  author =	 {Pagès, J. and Collewet, C. and Chaumette, F. and Salvi, J.},
  title =	 {Plane-to-plane positioning from image-based visual servoing
                  and structured light},
  booktitle =	 {IEEE/RSJ Int. Conf. on Intelligent Robots and Systems,
                  IROS'04},
  volume =	 {1},
  pages =	 {1004--1009},
  year =	 {2004},
  adresse =	 {Sendai, Japon},
  address =	 {Sendai, Japan},
  month =	 {september},
  keyword =	 {visual servoing, robotics},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_iros_pages.pdf},
  abstract =	 {In this paper some advantages of using structured light for
                  designing visual features in a visual servoing control scheme
                  are presented. The typical advantage of structured light in
                  any computer vision application is that the image processing
                  is simplified. However, we point out that a more important
                  advantage of using structured light in visual servoing is the
                  possibility to create and to choose the visual features. The
                  potentiality of structured light in the visual servoing field
                  is shown in this paper by focusing on a specific task of
                  positioning a camera parallel to a planar object so that
                  three degrees of freedom are controlled. Concretely, we show
                  how a diagonal interaction matrix can be designed with the
                  aid of a suitable structured light
                  configuration. Furthermore, the flexibility of the structured
                  light approach allows the condition number of the interaction
                  matrix to be optimised and to adjust its sensitivity,
                  increasing the stability of the control law. Such a design
                  can also be used to reduce the non-linearities of the
                  interaction matrix in order to obtain a better 3D
                  trajectory.}
}

@misc{Pages04b,
  author =	 {Pagès, J. and Collewet, C. and Chaumette, F. and Salvi, J.},
  title =	 {Couplage asservissement visuel et lumière stucturée pour la
                  réalisation d'une tâche de positionnement plan à plan},
  howpublished = {18èmes Journées des Jeunes Chercheurs en Robotique},
  OPTpages =	 {},
  year =	 {2004},
  address =	 {Douai,},
  month =	 {septembre},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_jjcr_pages.pdf},
}

@InProceedings{Pressigout04a,
  author =	 {Pressigout, M. and Marchand, E.},
  title =	 {Model-free augmented reality by virtual visual servoing},
  booktitle =	 {IAPR Int. Conf. on Pattern Recognition, ICPR'04},
  pages =	 {887-891},
  year =	 {2004},
  volume =	 {2},
  adresse =	 {Cambridge, Royaume-Uni},
  address =	 {Cambridge, UK},
  month =	 aug,
  abstract =	 {This paper presents a method based on the virtual visual
                  servoing approach to achieve markerless augmented reality
                  applications. This work aims to realize this task using as
                  less prior 3D information as possible. Virtual visual
                  servoing techniques that leads to a non-linear minimization
                  approach allow us to estimate the 2D transformation between
                  two images of a video sequence which permits to achieve
                  augmented reality on this sequence. Thanks to the work that
                  has already been carried out in this domain, the presented
                  method is efficient and robust wrt. noise and occlusions. It
                  allows very realistic augmented videos with minimum knowledge
                  on the real environment.},
doi = {http://dx.doi.org/10.1109/ICPR.2004.1334401},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_icpr_pressigout.pdf},
  keyword =	 {visual servoing, virtual visual servoing, augmented reality}
}

@InProceedings{Remazeilles04a,
  Author =	 {Remazeilles, A. and Chaumette, F. and Gros, P.},
  Title =	 {Contrôle des mouvements d'un robot à l'aide d'une mémoire
                  visuelle},
  BookTitle =	 {14ème Congrès Francophone AFRIF-AFIA de Reconnaissance des
                  Formes et Intelligence Artificielle, RFIA 2004},
  Address =	 {Toulouse, France},
  Month =	 {January},
  type =	 nationale,
  Year =	 {2004},
  abstract =	 {Cet article propose une nouvelle approche pour déterminer les
                  mouvements d'un robot en se basant sur les images fournies
                  par une caméra embarquée. Elle a la particularité de
                  s'affranchir d'une étape de reconstruction de
                  l'environnement, sans pour autant limiter les
                  déplacements. Pour cela, nous utilisons une base d'images
                  décrivant l'espace de navigation. De cette base est extraite
                  une série d'images qui définissent la zone que doit traverser
                  le robot pour atteindre la position désirée. Les mouvements
                  du robot sont déterminés en ligne en s'appuyant seulement sur
                  des primitives d'intérêt extraites des images. Une méthode
                  basée sur les champs de potentiel a été adaptée pour assurer
                  une visibilité suffisante de ces primitives tout au long du
                  déplacement. Des résultats expériment aux obtenus sur un
                  robot cartésien à six degrés de liberté sont présentés et
                  confirment la validité de notre approche.},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_rfia_remazeilles.pdf},
  keyword =	 { visual servoing, robotics}
}

@InProceedings{Remazeilles04b,
  Author =	 {Remazeilles, A. and Chaumette, F. and Gros, P.},
  title =	 {Robot motion control from a visual memory},
  booktitle =	 {IEEE Int. Conf. on Robotics and Automation, ICRA'04},
  pages =	 {4695-4700},
  year =	 {2004},
  volume =	 {4},
  address =	 {New Orleans, LA},
  adresse =	 {La Nouvelle-Orléans, Louisiane},
  month =	 {Avril},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_icra_remazeilles.pdf},
  abstract =	 {This article presents a new approach for robot motion
                  control, using images acquired by an on-board camera. A
                  particularity of this method is that it can avoid
                  reconstructing the entire scene without limiting the
                  displacements possible. To achieve this, an image base of the
                  environment is used to describe the navigation space. We
                  extract from this base a sequence of overlapping images which
                  define the zone that the robot must traverse, in order to
                  reach the desired position. Motions are computed on-line
                  using only points of interest extracted from these images. A
                  method based on potential field theory has been adapted in
                  order to ensure a suf cient visibility of these features
                  during the entire motion of the robot. Experimental results
                  obtained on a six degrees of freedom robotic system are
                  presented and confirm the validity of our approach. },
  keyword =	 { visual servoing, robotics}
}

@InProceedings{Tahri04a,
  Author =	 {Tahri, O. and Chaumette, F.},
  Title =	 {Image Moments: Generic Descriptors for Decoupled Image-based
                  Visual Servo},
  booktitle =	 {IEEE Int. Conf. on Robotics and Automation, ICRA'04},
  pages =	 {1185-1190},
  year =	 {2004},
  volume =	 {2},
  address =	 {New Orleans, LA},
  adresse =	 {La Nouvelle-Orléans, Louisiane},
  keyword =	 {visual servoing, robotics, moment},
  month =	 {Avril},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_icra_tahri.pdf},
  abstract =	 {Moments are generic and (usually) intuitive descriptors that
                  can be computed from several kinds of objects defined either
                  from closed contours (continuous object) or a set of points
                  (discrete object). In this paper, we propose to use moments
                  to design a decoupled image-based visual servo. The
                  analytical form of the interaction matrix related to the
                  moments computed for a discrete object is derived, and we
                  show that it is different of the form obtained for a
                  continuous object. Six visual features are selected to design
                  a decoupled control scheme when the object is parallel to the
                  image plane. This nice property is then generalized to the
                  case where the desired object position is not parallel to the
                  image plane. Finally, experimental results are presented to
                  illustrate the validity of our approach and its robustness
                  with respect to modeling errors. },
  keyword =	 { visual servoing, robotics, modelisation}
}

@PhdThesis{Alhaj04a,
  author =	 {{Alhaj (Cemagref Rennes)}, A.},
  title =	 {Apports de la vision dynamique en asservissement visuel},
  school =	 {Université de Rennes 1, Cemagref Rennes},
  year =	 {2004},
  month =	 {juin},
  abstract =	 {Le sujet de cette thèse concerne la vision robotique. Plus
                  précisément, nous nous intéressons à la réalisation de tâches
                  de positionnement par asservissement visuel en nous
                  restreignant toutefois au cas où l'objet observé est
                  immobile. En revanche, nous ne formulons pas d autre
                  hypothèse en particulier quant à sa forme puisque nous la
                  supposons inconnue. De même, nous supposons l image en
                  position désirée du porteur également inconnue. De ce fait,
                  nous réalisons parallèlement à la tâche de positionnement une
                  phase de reconstruction 3D permettant ainsi l obtention du
                  plan tangent en un point situé dans une zone d intérêt de l
                  objet. Une loi de commande de type asservissement visuel
                  2D1/2 permet ensuite de positionner et d orienter
                  indifféremment la caméra par rapport à ce plan tangent. Les
                  paramètres de courbure sont également calculés, plus dans un
                  souci de connaissance de l objet observé en vue d une
                  utilisation dans une application éventuelle que pour une
                  utilisation dans la loi de commande. D un point de vue
                  reconstruction 3D, nous avons investigué les approches
                  indirectes, basées sur les mesures de la vitesse 3D de la
                  caméra et du mouvement projeté, mouvement obtenu grÆace à l
                  utilisation d un modèle de mouvement
                  paramétrique. L'expression de ce modèle dépend bien entendu
                  de la forme de l'objet, plane ou non, et cette connaissance
                  est exploitée lorsqu elle est disponible. En revanche, si
                  elle ne l'est pas, nous nous sommes efforcés d'unifier les
                  approches proposées afin de disposer d'une unique approche,
                  indépendante de ce qui est observé. Cette fa¸con de faire
                  conduit à certaines contraintes à respecter par la loi de
                  commande. Par ailleurs, deux types d'approche ont été
                  étudiés, les approches continue et discrète. Ces approches
                  ont été comparées, et une étude de la précision de la
                  reconstruction vis-à-vis de l influence de certains
                  paramètres (vitesse de la caméra, paramètres du modèle de
                  mouvement, paramètres de calibration) a été menée conduisant
                  à certains cas plus favorables que d autres et qui sont
                  exploités lors du processus d'asservissement
                  visuel. Finalement, des résultats de simulations ou
                  d'expérimentation valident les résultats théoriques obtenus.},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_these_alhaj.pdf}
}

@PhdThesis{Tahri04b,
  author =	 {Tahri, O.},
  title =	 {Application des moments à l'asservissement visuel et au
                  calcul de pose},
  school =	 {Université de Rennes 1, mention informatique},
  year =	 {2004},
  address =	 {Rennes},
  month =	 {March},
  abstract =	 { <p>La thématique de cette thèse s'inscrit dans le domaine de
                  l'asservissement visuel qui consiste à contr\^oler les
                  mouvements d'un système robotique en utilisant des
                  informations fournies par un capteur de vision. Les
                  techniques classiques sont basées sur des primitives
                  géométriques particulières : coordonnées de point, équations
                  de droites, équations d'ellipses, etc. Par conséquent, la
                  famille des scènes concernées est limitée à des scènes très
                  simples. Dans cette thèse, on propose d'utiliser les moments
                  d'un objet dans l'image, ces derniers pouvant en effet
                  caractériser des objets de forme beaucoup plus
                  complexe. <p>Dans un premier temps, nous proposons une
                  nouvelle méthode basée sur un calcul variationnel pour
                  déterminer des formules analytiques de moments invariants. La
                  méthode présentée permet de déterminer des moments invariants
                  aux rotations, aux translations et aux changements
                  d'échelle. Nous exploitons ensuite ces résultats pour choisir
                  six informations visuelles afin contrôler les six degrés de
                  liberté d'une caméra. L'objectif est de réaliser un schéma de
                  commande découplé et de minimiser les non linéarités du
                  système. L'ensemble de ces résultats a été validé en
                  utilisant des objets de forme plane et définis soit par une
                  distribution continue soit par un ensemble de points. <p> La
                  deuxième partie de la thèse porte sur le calcul de pose. En
                  disposant d'un modèle 3D de l'objet, il s'agit de
                  reconstruire la position et l'orientation de cet objet dans
                  le repère de la caméra en utilisant l'image
                  correspondante. Notre approche consiste à commander
                  virtuellement les mouvements de la caméra de telle sorte qu'à
                  sa position finale, la projection du modèle CAO de l'objet
                  corresponde à l'image acquise. Cette méthode est équivalente
                  à une méthode non linéaire sujette à minima locaux. Pour
                  résoudre ce problème, nous utilisons une méthode
                  d'initialisation efficace basée sur le calcul d'une table
                  bidimensionelle. Nous proposons enfin une méthode de calcul
                  de pose partielle n'utilisant pas la connaissance du modè le
                  CAO de l'objet. Elle revient à utiliser les moments pour
                  estimer la collinéation entre deux images d'un objet plan. },
  note =	 { Le jury était composé de Phillipe Martinet (LASMEA), Patrick
                  Rives (INRIA Sophia), Seth Hutchinson (Univ. Champaign
                  Urbana), Peter Sturm (INRIA Grenoble), Patrick Bouthemy
                  (IRISA), François Chaumette (IRISA).},
  keyword =	 { visual servoing, robotics, modelisation},
  pdf =		 {http://www.irisa.fr/lagadic/pdf/2004_these_tahri.pdf}
}

@PhdThesis{Remazeilles04c,
  author =	 {Remazeilles, A.},
  title =	 {Navigation à partir d'une mémoire d'images},
  school =	 {Université de Rennes 1, mention informatique},
  year =	 {2004},
  address =	 {Rennes},
  month =	 {dec},
  abstract =	 { <p> Ces travaux portent sur la définition d'un formalisme
                  pour la réalisation de tâches de navigation robotique
                  contrôlées par la vision. <p> L'environnement de navigation
                  du système robotique est représenté de manière topologique,
                  ce qui permet de s'afranchir de la connaissance d'un modèle
                  3D de la scène. Une base d'images acquise lors d'une phase
                  d'apprentissage décrit visuellement cet environnement. Ces
                  images sont organisées sous la forme d'un graphe topologique,
                  graphe qui permet de décrire la possibilité et la facilité de
                  se déplacer d'une image vers une autre. <p> Une localisation
                  qualitative du système robotique dans son environnement est
                  effectuée en utilisant des techniques de recherche
                  d'images. Les positions initiales et désirées peuvent ensuite
                  être mises en relation en effectuant une recherche de chemin
                  dans le graphe. Une génération de graphes hiérarchiques à
                  partir du graphe initial permet de diminuer l'espace de
                  recherche de ce chemin. <p> Les mouvements du robots sont
                  contrôlées en ligne, à partir de ce chemin d'images. Ce
                  dernier constituent une description visuelle de
                  l'environnement que doit observer la caméra durant son
                  déplacement. Les différentes images le constituant ne sont
                  pas considérées comme un ensemble de positions intermédiaires
                  que doit successivement atteindre le robot. Le système
                  robotique se déplace afin d'observer dans de bonnes
                  conditions les différents ensembles d'amers visuels appariés
                  entre les images de ce chemin. Trois informations visuelles
                  sont proposées pour spécifier si la visibilité d'un ensemble
                  de points est satisfaisante. Une loi de commande combinant
                  les principes d'asservissement visuel et des fonctions de
                  potentiels fournit alors le mouvement permettant de
                  satisfaire simultanément ces trois contraintes. <p> Des
                  résultats expérimentaux de navigation ont été obtenus sur le
                  robot cartésien de l'IRISA, dans le cas de scènes planes et
                  de mouvements plans. Des résultats de simulation valident
                  l'approche pour des environnements 3D, dans le cas de
                  systèmes robotiques à six degrés de liberté, et de systèmes
                  se déplaçant sur un plan. },
  note =	 { Le jury était composé de Michel Devy (Directeur de
                  Recherche, CNRS LAAS, Toulouse), Patrick Rives (Directeur de
                  Recherche, INRIA, Sophia-Antipolis), Jean
                  Camillerapp(Professeur, INSA, Rennes), Michel Dhome
                  (Directeur de Recherche, CNRS, LASMEA, Clermont-Ferrand),
                  José Santos-Victor, Professeur, IST de Lisbonne, Portugal),
                  Francois Chaumette (Directeur de Recherche INRIA, IRISA,
                  Rennes), Patrick Gros (Chargé de Recherche (HDR) CNRS, IRISA,
                  Rennes) },
  keyword =	 { visual servoing, robotics, modelisation},
  pdf =		 {ftp://ftp.irisa.fr/techreports/theses/2004/remazeilles.pdf}
}
